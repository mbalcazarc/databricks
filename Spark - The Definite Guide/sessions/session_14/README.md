## Session 14
### Chapters 22 & 23 - Event-Time and Stateful Processing

![Banner Session 14](../../assets/banner_session_14.png)

### Resumen
En la sesión anterior, hemos conocido los aspectos relevantes del API de Structured Streaming. Ahora vamos a trabajar con el tema del procesamiento de event time. Con este modelo de procesamiento se busca analizar la información con respecto al tiempo en que fue creado. Esto tiene implicaciones importantes durante el procesamiento en streaming, especialmente en entornos de producción, ya que sería necesario mantener un estado relevante para actualizar la información antes de meterlo al sink.

Durante la sesión, se presentó un pequeño proyecto de ingesta de datos del Twitter a Apache Kafka y lectura de los mismos en streaming dentro de PySpark. El repositorio de este proyecto se encuentra [aquí](https://github.com/kauvinlucas/pyspark-stateful-processing-with-twitter-kafka)

#### Grabación de la sesión
[![Watch Session 14](../../assets/youtube.png)](https://www.youtube.com/watch?v=PAXTLdXDhDk)

#### Nuestras redes sociales
* [Youtube](https://www.youtube.com/channel/UCqFCoUEvxR23ymmih0GD7mQ?sub_confirmation=1 'Subscríbate al canal')
* [Linkedin](https://www.linkedin.com/company/data-engineering-latam/ 'Síganos en Linkedin')
* [Facebook](https://www.facebook.com/dataengineeringlatam/ 'Síganos en Facebook')
* [Website](https://beacons.ai/dataengineeringlatam 'Nuestro website')
